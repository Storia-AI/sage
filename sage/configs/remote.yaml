llm-retriever: true
llm-provider: anthropic
reranker-provider: none

# The settings below (embeddings and vector store) are only relevant when setting --no-llm-retriever

# Embeddings
embedding-provider: openai
embedding-model: text-embedding-3-small
tokens-per-chunk: 800
chunks-per-batch: 2000
# Vector store
vector-store-provider: pinecone
pinecone-index-name: sage
hybrid-retrieval: true
